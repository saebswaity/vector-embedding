# Vector Embedding and Dimensionality Reduction

This Python code demonstrates dimensionality reduction for one-hot encoding vectors in natural language processing. 
It uses a reduction matrix to represent words as numerical vectors, measuring similarity through dot products. 
The process involves arranging dot products in a matrix and leveraging the symmetric nature of the resulting Gram matrix.
The code provides a clear visualization of the reduced vectors in 3D space. 

![Vector Embedding](https://github.com/saebswaity/vector-embedding/blob/main/vector%20embedding.png)
